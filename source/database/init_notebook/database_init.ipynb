{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Translation Memory Database Initialization\n",
    "\n",
    "This notebook allows you to create and initialize the translation memory database for the machine translation pipeline. The translation memory database stores previously translated text pairs with their embeddings to enable similarity search and improve translation consistency.\n",
    "\n",
    "## What this notebook does:\n",
    "\n",
    "- Loads sample translation data (French to German)\n",
    "- Generates embeddings for source and target text using Amazon Bedrock\n",
    "- Populates the Aurora PostgreSQL translation memory table\n",
    "- Tests vector similarity search functionality\n",
    "\n",
    "The translation memory enables the pipeline to find similar previously translated content and suggest consistent translations for recurring text patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisites",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "1. All CDK stacks must have been successfully deployed\n",
    "2. The Translation Memory Aurora PostgreSQL cluster must be running\n",
    "3. The translation_memory table must have been created with vector extension enabled\n",
    "4. Amazon Bedrock access must be configured for embedding generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install the required Python libraries for database initialization and embedding generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-deps",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all the required prerequiste libraries - approx 3 min to complete\n",
    "%pip install -r requirements.txt\n",
    "%pip install -r bedrock_requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embeddings-section",
   "metadata": {},
   "source": [
    "## Generate Embeddings for Sample Data\n",
    "\n",
    "This section demonstrates how to generate vector embeddings for translation pairs using Amazon Bedrock's Titan embedding model. These embeddings enable semantic similarity search in the translation memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-data",
   "metadata": {},
   "source": [
    "### Load Sample Translation Data\n",
    "\n",
    "Load the WMT19 French-German translation dataset to populate the translation memory with high-quality translation pairs. The sample data is borrowed from the [WMT19](https://huggingface.co/datasets/wmt/wmt19) open source dataset available on HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "init-bedrock",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "bedrock = boto3.client(service_name=\"bedrock\")\n",
    "bedrock_runtime = boto3.client(service_name=\"bedrock-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-csv",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data of csv\n",
    "df = pd.read_csv('../../../sample_data/wmt19_fr-de.csv')\n",
    "print(\"Total number of records : {}\".format(len(df.index)))\n",
    "\n",
    "display(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generate-embeddings",
   "metadata": {},
   "source": [
    "### Generate Text Embeddings\n",
    "\n",
    "Use Amazon Bedrock's Titan Text Embeddings v2 model to convert text into high-dimensional vectors that capture semantic meaning. These embeddings enable similarity search for finding relevant translation memories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedding-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(query):\n",
    "    \n",
    "    payLoad = json.dumps({'inputText': query })\n",
    "    \n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        body=payLoad, \n",
    "        modelId='amazon.titan-embed-text-v2:0',\n",
    "        accept=\"application/json\", \n",
    "        contentType=\"application/json\" )\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    return(response_body.get(\"embedding\"))\n",
    "    \n",
    "source_embeddings = generate_embeddings(df.iloc[1].get('source'))\n",
    "\n",
    "print (\"Number of dimensions : {}\".format(len(source_embeddings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "batch-embeddings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for translation pairs - approx 3 min to complete\n",
    "# Processing first 20 records for demonstration. If there are any failures, please rerun the cell.\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=8)\n",
    "\n",
    "df_20 = df.head(20)\n",
    "df_20['target_embeddings'] = df_20['target'].apply(generate_embeddings)\n",
    "df_20['source_embeddings'] = df_20['source'].apply(generate_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-database",
   "metadata": {},
   "source": [
    "### Load Data into Translation Memory Table\n",
    "\n",
    "Insert the translation pairs and their embeddings into the Aurora PostgreSQL database using the RDS Data API. The embeddings are stored as vector data types for efficient similarity search.\n",
    "\n",
    "**Note:** Replace the placeholder values in the next cell with the actual CloudFormation output values from your DatabaseStack deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "database-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 \n",
    "import json \n",
    "\n",
    "# Replace these placeholders with actual values from your CDK deployment outputs:\n",
    "# - DatabaseSecretArn: The ARN of the Aurora credentials secret\n",
    "# - DatabaseClusterArn: The ARN of the Aurora PostgreSQL cluster\n",
    "# - DatabaseName: The name of the translation memory database\n",
    "\n",
    "secret_arn = \"<REPLACE_WITH_DatabaseSecretArn_OUTPUT>\"\n",
    "cluster_arn = \"<REPLACE_WITH_DatabaseClusterArn_OUTPUT>\"\n",
    "database_name = \"<REPLACE_WITH_DatabaseName_OUTPUT>\"\n",
    "\n",
    "def insert_data(source_lang, target_lang, source_text, target_text, source_text_embedding, target_text_embedding):\n",
    "    rds_data = boto3.client('rds-data')\n",
    "\n",
    "    sql = \"\"\"\n",
    "          INSERT INTO translation_memory(source_text, target_text, source_lang, target_lang, source_text_embedding, target_text_embedding)\n",
    "          VALUES( :source_text, :target_text, :source_lang, :target_lang, CAST(:source_text_embedding AS VECTOR), CAST(:target_text_embedding AS VECTOR))\n",
    "          \"\"\"\n",
    "\n",
    "    param2 = {'name':'source_text', 'value':{'stringValue': source_text}}\n",
    "    param3 = {'name':'target_text', 'value':{'stringValue': target_text}}\n",
    "    param4 = {'name':'source_lang', 'value':{'stringValue': source_lang}}\n",
    "    param5 = {'name':'target_lang', 'value':{'stringValue': target_lang}}\n",
    "    param6 = {'name':'source_text_embedding', 'value':{'stringValue': source_text_embedding}}\n",
    "    param7 = {'name':'target_text_embedding', 'value':{'stringValue': target_text_embedding}}\n",
    "    param_set = [param2, param3, param4, param5, param6, param7]\n",
    " \n",
    "    response = rds_data.execute_statement(\n",
    "        resourceArn = cluster_arn, \n",
    "        secretArn = secret_arn, \n",
    "        database = database_name, \n",
    "        sql = sql,\n",
    "        parameters = param_set)\n",
    "\n",
    "for  index, record in df_20.iterrows():\n",
    "    insert_data(\"fr\", \"de\", record['source'], record['target'], str(record['source_embeddings']), str(record['target_embeddings']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-search",
   "metadata": {},
   "source": [
    "## Test Translation Memory Vector Search\n",
    "\n",
    "Verify that the translation memory is working correctly by performing a similarity search. This demonstrates how the system finds the most similar source texts and their corresponding translations based on vector embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similarity-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from IPython.display import display, Markdown, Latex, HTML\n",
    "\n",
    "def similarity_search(search_text):\n",
    "    \n",
    "    embedding = numpy.array(generate_embeddings(search_text))\n",
    "    rds_data = boto3.client('rds-data')\n",
    "    embedding_str = str(embedding.tolist())\n",
    "    sql_text = f\"SELECT unique_id, source_text, target_text FROM translation_memory ORDER BY source_text_embedding <=> CAST('{embedding_str}' AS VECTOR) limit 3;\"\n",
    "    \n",
    "    response = rds_data.execute_statement(\n",
    "        resourceArn = cluster_arn, \n",
    "        secretArn = secret_arn, \n",
    "        database = database_name, \n",
    "        sql = sql_text\n",
    "    )\n",
    "\n",
    "    print(response)\n",
    "\n",
    "similarity_search(\"Reprise de la session\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
